{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConditionalGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPRBRqNyEOhbRlyFRapnHS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kotetsu-n/pytorch_GANs_impl/blob/master/ConditionalGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oslUjJp03xN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Refered to\n",
        "https://github.com/malzantot/Pytorch-conditional-GANs/blob/master/conditional_dcgan.py\n",
        "'''\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=100, num_classes=10, img_shape=(1,32,32)):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # is it Okay to change one-hot-vector?\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.label_emb = nn.Embedding(self.num_classes, self.num_classes)\n",
        "        self.img_shape = img_shape\n",
        "\n",
        "        def block(in_dim, out_dim, normalize=True):\n",
        "            layers = [nn.Linear(in_dim, out_dim)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_dim))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(self.latent_dim+self.num_classes, 128),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        gen_input = torch.cat((self.label_emb(labels), z), -1)\n",
        "        out = self.model(gen_input)\n",
        "        out = out.view(out.size(0), *self.img_shape)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_classes=10, img_shape=(1,32,32)):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.img_shape = img_shape\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(self.num_classes+int(np.prod(self.img_shape)), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        d_in = torch.cat((x.view(x.size(0), -1), self.label_emb(labels)), -1)\n",
        "        out = self.model(d_in)\n",
        "\n",
        "        return out\n",
        "\n",
        "def download_MNIST(img_size, batch_size):\n",
        "    os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(\n",
        "            \"../../data/mnist\",\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transforms.Compose(\n",
        "                [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "            ),\n",
        "        ),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "def train_model(G, D, opt, dataloader, num_epochs):\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    print('currently use:', device)\n",
        "\n",
        "    # optimization\n",
        "    g_optimizer = torch.optim.Adam(G.parameters(), opt.lr_g, [opt.b1, opt.b2])\n",
        "    d_optimizer = torch.optim.Adam(D.parameters(), opt.lr_d, [opt.b1, opt.b2])\n",
        "\n",
        "    # criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    G.to(device)\n",
        "    D.to(device)\n",
        "\n",
        "    G.train()\n",
        "    D.train()\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    os.makedirs('./images/', exist_ok=True)\n",
        "    \n",
        "    iteration = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        t_epoch_start = time.time()\n",
        "        epoch_g_loss = 0.0\n",
        "        epoch_d_loss = 0.0\n",
        "\n",
        "        print('----------')\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('----------')\n",
        "        print(' (train) ')\n",
        "\n",
        "        for i, (imgs, labels) in enumerate(dataloader):\n",
        "            if imgs.size()[0] == 1:\n",
        "                continue\n",
        "\n",
        "            real_imgs = imgs.to(device)\n",
        "            real_labels = labels.to(device)\n",
        "\n",
        "            batch_size = imgs.size()[0]\n",
        "            label_1 = torch.full((batch_size,1), 1.0).to(device)\n",
        "            label_0 = torch.full((batch_size,1), 0.0).to(device)\n",
        "\n",
        "            '''\n",
        "             train generator\n",
        "            '''\n",
        "            g_optimizer.zero_grad()\n",
        "\n",
        "            # generate noises for generator\n",
        "            z = torch.randn(batch_size, opt.latent_dim).to(device)\n",
        "            fake_labels = torch.randint(0, opt.num_classes, (batch_size,)).to(device)\n",
        "            \n",
        "            fake_imgs = G(z, fake_labels)\n",
        "            d_out_fake = D(fake_imgs, fake_labels)\n",
        "\n",
        "            g_loss = criterion(d_out_fake, label_1)\n",
        "\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "            '''\n",
        "             train discriminator\n",
        "            '''\n",
        "\n",
        "            d_optimizer.zero_grad()\n",
        "\n",
        "            # loss for real images\n",
        "            d_out_real = D(real_imgs, real_labels)\n",
        "            d_loss_real = criterion(d_out_real, label_1)\n",
        "            \n",
        "            # loss for fake images\n",
        "            d_out_fake = D(fake_imgs.detach(), fake_labels)\n",
        "            d_loss_fake = criterion(d_out_fake, label_0)\n",
        "\n",
        "            d_loss = (d_loss_real + d_loss_fake) * 0.5\n",
        "\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "\n",
        "            epoch_d_loss += d_loss.item()\n",
        "            epoch_g_loss += g_loss.item()\n",
        "            iteration += 1\n",
        "     \n",
        "            # print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            #       % (epoch, opt.num_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "            # )\n",
        "\n",
        "            def sample_image(generator, iteration, opt, device, n_row=10):\n",
        "                batches_done=iteration\n",
        "                z = torch.randn(n_row ** 2, opt.latent_dim).to(device)\n",
        "                labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
        "                labels = torch.tensor(labels).to(device)\n",
        "                gen_imgs = generator(z, labels)\n",
        "                save_image(gen_imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
        "\n",
        "            if iteration % opt.sample_interval == 0:\n",
        "                sample_image(G, iteration, opt, device, n_row=10)\n",
        "        \n",
        "        t_epoch_finish = time.time()\n",
        "        print('-------------')\n",
        "        print('epoch {} || Epoch_D_Loss:{:.4f} ||Epoch_G_Loss:{:.4f}'.format(\n",
        "            epoch, epoch_d_loss/iteration, epoch_g_loss/iteration))\n",
        "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
        "        t_epoch_start = time.time()\n",
        "\n",
        "    return G, D\n",
        "\n",
        "def train(opt):\n",
        "    dataloader = download_MNIST(img_size=opt.img_size, batch_size=opt.batch_size)\n",
        "\n",
        "    batch_iterator = iter(dataloader)\n",
        "    imgs = next(batch_iterator)\n",
        "    # print(imgs.size())\n",
        "\n",
        "    G = Generator(latent_dim=opt.latent_dim, num_classes=opt.num_classes, \n",
        "                  img_shape=(opt.channels,opt.img_size, opt.img_size))\n",
        "    D = Discriminator(num_classes=opt.num_classes, \n",
        "                      img_shape=(opt.channels,opt.img_size, opt.img_size))\n",
        "\n",
        "    # G.apply(weights_init)\n",
        "    # D.apply(weights_init)\n",
        "\n",
        "    num_epochs = opt.num_epochs\n",
        "    G_update, D_update = train_model(\n",
        "        G, D, opt, dataloader=dataloader, num_epochs=num_epochs)\n",
        "\n",
        "    return G_update, D_update\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27Is9Iih1LXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__=='__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
        "    parser.add_argument(\"--lr_d\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
        "    parser.add_argument(\"--lr_g\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
        "    parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
        "    parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
        "    parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
        "    parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
        "    parser.add_argument(\"--num_classes\", type=int, default=10, help=\"number of classes for dataset\")\n",
        "    parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
        "    parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
        "    parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image sampling\")\n",
        "    opt = parser.parse_args(args=['--num_epochs', '200'])\n",
        "    print(opt)\n",
        "\n",
        "    train(opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-43pD95O1u7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}